{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe76597-0945-408c-b9ec-6fae500bb868",
   "metadata": {},
   "source": [
    "# Assessment: Analyzing Soccer Data\n",
    "\n",
    "TODO: add intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0f25e-ff42-421a-acfb-2316493af030",
   "metadata": {},
   "source": [
    "## 0. Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2aa8a6-a675-46c7-b8ab-96671cc30ef7",
   "metadata": {},
   "source": [
    "### a. Load linting tool, create spark session, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf7ed285-6170-4bb2-9837-c4fc1445510e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3bebcd6-9f2f-4d33-b972-099e32588052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "# Create spark app\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"rb assessment app\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857e9deb-b19c-4ab5-a9a9-525096354ca2",
   "metadata": {},
   "source": [
    "### a. Data Engineering for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7362a1d8-3e00-484a-a6fb-782ef181cab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- home_team_name: string (nullable = true)\n",
      " |-- away_team_name: string (nullable = true)\n",
      " |-- home_team_result: double (nullable = false)\n",
      " |-- away_team_result: double (nullable = false)\n",
      "\n",
      "    home_team_name            away_team_name  home_team_result  \\\n",
      "0    Bayern Munich              Hamburger SV               1.0   \n",
      "1         Augsburg             Hertha Berlin               0.0   \n",
      "2    Werder Bremen                Schalke 04               0.0   \n",
      "3     FSV Mainz 05                Ingolstadt               0.0   \n",
      "4     Darmstadt 98               Hannover 96               0.5   \n",
      "..             ...                       ...               ...   \n",
      "301   Darmstadt 98  Borussia Mönchengladbach               0.0   \n",
      "302  Bayern Munich               Hannover 96               1.0   \n",
      "303   FSV Mainz 05             Hertha Berlin               0.5   \n",
      "304  Werder Bremen       Eintracht Frankfurt               1.0   \n",
      "305      Wolfsburg             VfB Stuttgart               1.0   \n",
      "\n",
      "     away_team_result  \n",
      "0                 0.0  \n",
      "1                 1.0  \n",
      "2                 1.0  \n",
      "3                 1.0  \n",
      "4                 0.5  \n",
      "..                ...  \n",
      "301               1.0  \n",
      "302               0.0  \n",
      "303               0.5  \n",
      "304               0.0  \n",
      "305               0.0  \n",
      "\n",
      "[306 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "bl_results_spark_df = (\n",
    "    # read matches folder\n",
    "    spark\n",
    "    .read\n",
    "    .json(\n",
    "        \"data/matches/*/\",\n",
    "        multiLine=True\n",
    "    )\n",
    "    # filter 1. Bundesliga 2015/16 matches\n",
    "    .where(\n",
    "        func.col(\"competition.competition_name\").eqNullSafe(\"1. Bundesliga\")\n",
    "        & func.col(\"season.season_name\").eqNullSafe(\"2015/2016\")\n",
    "    )\n",
    "    # order by date to make sure that the ELO function is used approprietly\n",
    "    .orderBy(func.to_date(\"match_date\"))\n",
    "    # perform the mapping to get one row for each team and match\n",
    "    # the associated result is:\n",
    "    # - win = 1\n",
    "    # - draw = 0.5\n",
    "    # - loss = 0\n",
    "    .select(\n",
    "        func.col(\n",
    "            \"home_team.home_team_name\"\n",
    "        ).alias(\"home_team_name\"),\n",
    "        func.col(\n",
    "            \"away_team.away_team_name\"\n",
    "        ).alias(\"away_team_name\"),\n",
    "        func.coalesce(\n",
    "            func.when(func.expr(\"home_score > away_score\"), 1),\n",
    "            func.when(func.expr(\"home_score < away_score\"), 0),\n",
    "            func.lit(0.5)\n",
    "        ).alias(\"home_team_result\"),\n",
    "        func.coalesce(\n",
    "            func.when(func.expr(\"home_score > away_score\"), 0),\n",
    "            func.when(func.expr(\"home_score < away_score\"), 1),\n",
    "            func.lit(0.5)\n",
    "        ).alias(\"away_team_result\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# print schema for verification\n",
    "bl_results_spark_df.printSchema()\n",
    "\n",
    "# cache result to pandas df\n",
    "bl_result_df = bl_results_spark_df.toPandas()\n",
    "# display resulting df\n",
    "print(bl_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6168bb58-c284-4b28-90ac-8d3194e545b5",
   "metadata": {},
   "source": [
    "## 1. Task 1 - Elo Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e0f69-0b1d-458b-83a3-eaed22716528",
   "metadata": {},
   "source": [
    "### a. Develop a function to implement the ELO Rating System with arbitrary K and s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24c9df10-2348-46d3-9c59-8733f4cd8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def predict(rating_a, rating_b, s=15):\n",
    "    return 1 / (1 + math.pow(10, -(rating_a - rating_b) / s))\n",
    "\n",
    "def update_elo(rating_a, rating_b, outcome, s=15, K=15):\n",
    "    # expected outcome\n",
    "    pred = predict(rating_a, rating_b, s=15)\n",
    "    # step\n",
    "    return rating_a + K * (outcome - pred)\n",
    "\n",
    "def elo(results, s=15, K=15, R_0=100):\n",
    "    # init ratings\n",
    "    ratings = {team_name: R_0 for team_name in results[\"home_team_name\"].unique()}\n",
    "    for index, row in results.iterrows():\n",
    "        ratings[row[\"home_team_name\"]] = update_elo(\n",
    "            ratings[row[\"home_team_name\"]], \n",
    "            ratings[row[\"away_team_name\"]], \n",
    "            row[\"home_team_result\"],\n",
    "            s, K\n",
    "        )\n",
    "        ratings[row[\"away_team_name\"]] = update_elo(\n",
    "            ratings[row[\"away_team_name\"]], \n",
    "            ratings[row[\"home_team_name\"]], \n",
    "            row[\"away_team_result\"],\n",
    "            s, K\n",
    "        )\n",
    "    return dict(sorted(ratings.items(), key=operator.itemgetter(1), reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a046611-f2bf-4f2a-a6af-241a0fb8590e",
   "metadata": {},
   "source": [
    "### b. Apply the rating system to 1. Bundesliga 2015/2016 Season with starting values R0 = 100, s = 15 and K = 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8e352067-814e-46ca-9c47-825062f45735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Borussia Mönchengladbach': 128.73684750507124,\n",
       " 'Bayern Munich': 126.03882090784246,\n",
       " 'Werder Bremen': 122.53431008967196,\n",
       " 'Bayer Leverkusen': 119.86744451903735,\n",
       " 'Schalke 04': 116.7404982618847,\n",
       " 'Eintracht Frankfurt': 115.13792895836448,\n",
       " 'Borussia Dortmund': 113.14276236567889,\n",
       " 'FC Köln': 112.7931080154221,\n",
       " 'Hannover 96': 112.683637686516,\n",
       " 'Darmstadt 98': 104.6708369599969,\n",
       " 'Hoffenheim': 104.14444368636025,\n",
       " 'Ingolstadt': 104.05781546247819,\n",
       " 'Hamburger SV': 103.82508894341434,\n",
       " 'Wolfsburg': 103.54107736006338,\n",
       " 'Augsburg': 100.16514926109396,\n",
       " 'FSV Mainz 05': 98.21672472241177,\n",
       " 'Hertha Berlin': 96.401623690483,\n",
       " 'VfB Stuttgart': 88.0062841309003}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo(bl_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f045b9-c607-4d1a-b3ce-170c84a0a8b4",
   "metadata": {},
   "source": [
    "### c. Develop an approach that finds the optimal values for s and K based on that season and display the final ranking table at the end of the season.\n",
    "\n",
    "We could take the assumption that the optimal values for parameters s and K are the one that would minimize the discrepancy between the predicted outcome and actual match result for each step of that particular season.\n",
    "\n",
    "Let's define our loss function as the average brier score of our ELO Rating System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8a9892a6-c324-4f3a-9a8b-2b34773547bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23717873793811012"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def brier_score(results, s=15, K=15, R_0=100):\n",
    "    # init ratings\n",
    "    ratings = {team_name: R_0 for team_name in results[\"home_team_name\"].unique()}\n",
    "    agg = 0\n",
    "    for index, row in results.iterrows():\n",
    "        agg += (\n",
    "            (\n",
    "                predict(ratings[row[\"home_team_name\"]], ratings[row[\"away_team_name\"]], s) \\\n",
    "                - row[\"home_team_result\"]\n",
    "            ) ** 2 \\\n",
    "            + (\n",
    "                predict(ratings[row[\"away_team_name\"]], ratings[row[\"home_team_name\"]], s) \\\n",
    "                - row[\"away_team_result\"]\n",
    "            ) ** 2\n",
    "        )\n",
    "        ratings[row[\"home_team_name\"]] = update_elo(\n",
    "            ratings[row[\"home_team_name\"]], \n",
    "            ratings[row[\"away_team_name\"]], \n",
    "            row[\"home_team_result\"],\n",
    "            s, K\n",
    "        )\n",
    "        ratings[row[\"away_team_name\"]] = update_elo(\n",
    "            ratings[row[\"away_team_name\"]], \n",
    "            ratings[row[\"home_team_name\"]], \n",
    "            row[\"away_team_result\"],\n",
    "            s, K\n",
    "        )\n",
    "    return agg / (2 * results.shape[0])\n",
    "\n",
    "\n",
    "brier_score(bl_result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
