{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe76597-0945-408c-b9ec-6fae500bb868",
   "metadata": {},
   "source": [
    "# Assessment: Analyzing Soccer Data\n",
    "\n",
    "TODO: add intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0f25e-ff42-421a-acfb-2316493af030",
   "metadata": {},
   "source": [
    "## 0. Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2aa8a6-a675-46c7-b8ab-96671cc30ef7",
   "metadata": {},
   "source": [
    "### a. Load linting tool, create spark session, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7ed285-6170-4bb2-9837-c4fc1445510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bebcd6-9f2f-4d33-b972-099e32588052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "# Create spark app\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"rb assessment app\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857e9deb-b19c-4ab5-a9a9-525096354ca2",
   "metadata": {},
   "source": [
    "### a. Data Engineering for Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7362a1d8-3e00-484a-a6fb-782ef181cab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- home_team_name: string (nullable = true)\n",
      " |-- away_team_name: string (nullable = true)\n",
      " |-- home_team_result: double (nullable = false)\n",
      " |-- away_team_result: double (nullable = false)\n",
      "\n",
      "    home_team_name            away_team_name  home_team_result  \\\n",
      "0    Bayern Munich              Hamburger SV               1.0   \n",
      "1         Augsburg             Hertha Berlin               0.0   \n",
      "2    Werder Bremen                Schalke 04               0.0   \n",
      "3     FSV Mainz 05                Ingolstadt               0.0   \n",
      "4     Darmstadt 98               Hannover 96               0.5   \n",
      "..             ...                       ...               ...   \n",
      "301   Darmstadt 98  Borussia Mönchengladbach               0.0   \n",
      "302  Bayern Munich               Hannover 96               1.0   \n",
      "303   FSV Mainz 05             Hertha Berlin               0.5   \n",
      "304  Werder Bremen       Eintracht Frankfurt               1.0   \n",
      "305      Wolfsburg             VfB Stuttgart               1.0   \n",
      "\n",
      "     away_team_result  \n",
      "0                 0.0  \n",
      "1                 1.0  \n",
      "2                 1.0  \n",
      "3                 1.0  \n",
      "4                 0.5  \n",
      "..                ...  \n",
      "301               1.0  \n",
      "302               0.0  \n",
      "303               0.5  \n",
      "304               0.0  \n",
      "305               0.0  \n",
      "\n",
      "[306 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "bl_results_spark_df = (\n",
    "    # read matches folder\n",
    "    spark\n",
    "    .read\n",
    "    .json(\n",
    "        \"data/matches/*/\",\n",
    "        multiLine=True\n",
    "    )\n",
    "    # filter 1. Bundesliga 2015/16 matches\n",
    "    .where(\n",
    "        func.col(\"competition.competition_name\").eqNullSafe(\"1. Bundesliga\")\n",
    "        & func.col(\"season.season_name\").eqNullSafe(\"2015/2016\")\n",
    "    )\n",
    "    # order by date to make sure that the ELO function is used approprietly\n",
    "    .orderBy(func.to_date(\"match_date\"))\n",
    "    # perform the mapping to get one row for each team and match\n",
    "    # the associated result is:\n",
    "    # - win = 1\n",
    "    # - draw = 0.5\n",
    "    # - loss = 0\n",
    "    .select(\n",
    "        func.col(\n",
    "            \"home_team.home_team_name\"\n",
    "        ).alias(\"home_team_name\"),\n",
    "        func.col(\n",
    "            \"away_team.away_team_name\"\n",
    "        ).alias(\"away_team_name\"),\n",
    "        func.coalesce(\n",
    "            func.when(func.expr(\"home_score > away_score\"), 1),\n",
    "            func.when(func.expr(\"home_score < away_score\"), 0),\n",
    "            func.lit(0.5)\n",
    "        ).alias(\"home_team_result\"),\n",
    "        func.coalesce(\n",
    "            func.when(func.expr(\"home_score > away_score\"), 0),\n",
    "            func.when(func.expr(\"home_score < away_score\"), 1),\n",
    "            func.lit(0.5)\n",
    "        ).alias(\"away_team_result\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# print schema for verification\n",
    "bl_results_spark_df.printSchema()\n",
    "\n",
    "# cache result to pandas df\n",
    "bl_result_df = bl_results_spark_df.toPandas()\n",
    "# display resulting df\n",
    "print(bl_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6168bb58-c284-4b28-90ac-8d3194e545b5",
   "metadata": {},
   "source": [
    "## 1. Task 1 - Elo Rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e0f69-0b1d-458b-83a3-eaed22716528",
   "metadata": {},
   "source": [
    "### a. Develop a function to implement the ELO Rating System with arbitrary K and s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c9df10-2348-46d3-9c59-8733f4cd8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "import math\n",
    "import operator\n",
    "\n",
    "\n",
    "def predict(rating_a, rating_b, s=15):\n",
    "    \"\"\"Calculate the expected outcome for team A given ratings.\"\"\"\n",
    "    return 1 / (1 + math.pow(10, -(rating_a - rating_b) / s))\n",
    "\n",
    "\n",
    "def update_elo(rating_a, rating_b, outcome, s=15, K=15):\n",
    "    \"\"\"Update the ELO rating of a team after a match.\"\"\"\n",
    "    pred = predict(rating_a, rating_b, s)\n",
    "    return rating_a + K * (outcome - pred)\n",
    "\n",
    "\n",
    "def process_match(ratings, home_team, away_team, home_result, away_result,\n",
    "                  s, K):\n",
    "    \"\"\"Update ratings after processing a match.\"\"\"\n",
    "    # Update home team rating\n",
    "    ratings[home_team] = update_elo(\n",
    "        ratings[home_team], ratings[away_team], home_result, s, K\n",
    "    )\n",
    "    # Update away team rating\n",
    "    ratings[away_team] = update_elo(\n",
    "        ratings[away_team], ratings[home_team], away_result, s, K\n",
    "    )\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def initialize_ratings(teams, initial_rating=100):\n",
    "    \"\"\"Initialize the ratings for all teams.\"\"\"\n",
    "    return {team_name: initial_rating for team_name in teams}\n",
    "\n",
    "\n",
    "def elo(results, s=15, K=15, R_0=100):\n",
    "    \"\"\"Calculate the final ELO ratings for all teams.\"\"\"\n",
    "    # Initialize ratings\n",
    "    ratings = initialize_ratings(results[\"home_team_name\"].unique(), R_0)\n",
    "    for row in results.itertuples(index=False):\n",
    "        # Update ratings based on the match result\n",
    "        process_match(\n",
    "            ratings,\n",
    "            row.home_team_name,\n",
    "            row.away_team_name,\n",
    "            row.home_team_result,\n",
    "            row.away_team_result,\n",
    "            s, K\n",
    "        )\n",
    "    # Sort the ratings in descending order\n",
    "    return dict(\n",
    "        sorted(ratings.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a046611-f2bf-4f2a-a6af-241a0fb8590e",
   "metadata": {},
   "source": [
    "### b. Apply the rating system to 1. Bundesliga 2015/2016 Season with starting values R0 = 100, s = 15 and K = 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e352067-814e-46ca-9c47-825062f45735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Borussia Mönchengladbach': 128.73684750507124,\n",
       " 'Bayern Munich': 126.03882090784246,\n",
       " 'Werder Bremen': 122.53431008967196,\n",
       " 'Bayer Leverkusen': 119.86744451903735,\n",
       " 'Schalke 04': 116.7404982618847,\n",
       " 'Eintracht Frankfurt': 115.13792895836448,\n",
       " 'Borussia Dortmund': 113.14276236567889,\n",
       " 'FC Köln': 112.7931080154221,\n",
       " 'Hannover 96': 112.683637686516,\n",
       " 'Darmstadt 98': 104.6708369599969,\n",
       " 'Hoffenheim': 104.14444368636025,\n",
       " 'Ingolstadt': 104.05781546247819,\n",
       " 'Hamburger SV': 103.82508894341434,\n",
       " 'Wolfsburg': 103.54107736006338,\n",
       " 'Augsburg': 100.16514926109396,\n",
       " 'FSV Mainz 05': 98.21672472241177,\n",
       " 'Hertha Berlin': 96.401623690483,\n",
       " 'VfB Stuttgart': 88.0062841309003}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo(bl_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f045b9-c607-4d1a-b3ce-170c84a0a8b4",
   "metadata": {},
   "source": [
    "### c. Develop an approach that finds the optimal values for s and K based on that season and display the final ranking table at the end of the season.\n",
    "\n",
    "We could take the assumption that the optimal values for parameters s and K are the one that would minimize the discrepancy between the predicted outcome and actual match result for each step of that particular season.\n",
    "\n",
    "Let's define our loss function as the average brier score of our ELO Rating System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a9892a6-c324-4f3a-9a8b-2b34773547bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23717873793811076"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "def brier_score(results, s=15, K=15, R_0=100):\n",
    "    \"\"\"\n",
    "    Calculate the Brier score based on the predicted outcomes and actual\n",
    "    results.\n",
    "    \"\"\"\n",
    "    ratings = initialize_ratings(results[\"home_team_name\"].unique(), R_0)\n",
    "    total_brier_score = 0\n",
    "    for row in results.itertuples(index=False):\n",
    "        # Get teams predictions\n",
    "        home_rating = ratings[row.home_team_name]\n",
    "        away_rating = ratings[row.away_team_name]\n",
    "\n",
    "        home_pred = predict(home_rating, away_rating, s)\n",
    "        away_pred = 1 - home_pred\n",
    "\n",
    "        # Calculate Brier score for both teams\n",
    "        total_brier_score += (home_pred - row.home_team_result) ** 2\n",
    "        total_brier_score += (away_pred - row.away_team_result) ** 2\n",
    "\n",
    "        # Update ratings after the match\n",
    "        process_match(\n",
    "            ratings,\n",
    "            row.home_team_name,\n",
    "            row.away_team_name,\n",
    "            row.home_team_result,\n",
    "            row.away_team_result,\n",
    "            s, K\n",
    "        )\n",
    "\n",
    "    # Return the average Brier score\n",
    "    return total_brier_score / (2 * len(results))\n",
    "\n",
    "brier_score(bl_result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5333d-e78f-4b73-9e0c-9aa1aa257484",
   "metadata": {},
   "source": [
    "We are going to try finding good values for s and K params for brier_score in terms of brier score using bayesian optimization.\n",
    "It is a sampling method based on exploration and optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "210f769c-6fae-44ce-a0b4-ca66314b4529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     K     |     s     |\n",
      "-------------------------------------------------\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m-0.178   \u001b[39m | \u001b[35m18.07    \u001b[39m | \u001b[35m265.3    \u001b[39m |\n",
      "| \u001b[35m8        \u001b[39m | \u001b[35m-0.1779  \u001b[39m | \u001b[35m15.41    \u001b[39m | \u001b[35m206.1    \u001b[39m |\n",
      "| \u001b[35m44       \u001b[39m | \u001b[35m-0.1779  \u001b[39m | \u001b[35m22.83    \u001b[39m | \u001b[35m300.0    \u001b[39m |\n",
      "| \u001b[35m59       \u001b[39m | \u001b[35m-0.1779  \u001b[39m | \u001b[35m15.0     \u001b[39m | \u001b[35m200.4    \u001b[39m |\n",
      "| \u001b[35m94       \u001b[39m | \u001b[35m-0.1779  \u001b[39m | \u001b[35m18.18    \u001b[39m | \u001b[35m241.4    \u001b[39m |\n",
      "| \u001b[35m130      \u001b[39m | \u001b[35m-0.1779  \u001b[39m | \u001b[35m20.45    \u001b[39m | \u001b[35m271.1    \u001b[39m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "from functools import partial\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'s': (15, 300), 'K': (15, 30)}\n",
    "\n",
    "def neg_brier_score(s, K):\n",
    "    return - brier_score(bl_result_df, s=s, K=K)\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=neg_brier_score,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=32,\n",
    "    n_iter=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "001623b3-ffa6-4143-892b-f54f37d3b266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': np.float64(-0.17791904423717828), 'params': {'K': np.float64(20.44873714712105), 's': np.float64(271.1405558615955)}}\n"
     ]
    }
   ],
   "source": [
    "res = optimizer.max\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83d25d69-9eb6-47ca-8263-198828630250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bayern Munich': np.float64(239.10714701168303),\n",
       " 'Borussia Dortmund': np.float64(202.74555857602832),\n",
       " 'Bayer Leverkusen': np.float64(156.15384473399382),\n",
       " 'Borussia Mönchengladbach': np.float64(135.36332335175678),\n",
       " 'Schalke 04': np.float64(117.98494348740996),\n",
       " 'FSV Mainz 05': np.float64(106.89958701018837),\n",
       " 'FC Köln': np.float64(95.41208312462189),\n",
       " 'Hertha Berlin': np.float64(95.35379411470757),\n",
       " 'Wolfsburg': np.float64(83.21128855250517),\n",
       " 'Augsburg': np.float64(81.1916679150901),\n",
       " 'Hoffenheim': np.float64(80.0920946039107),\n",
       " 'Werder Bremen': np.float64(77.97082248179228),\n",
       " 'Hamburger SV': np.float64(74.23642223799513),\n",
       " 'Darmstadt 98': np.float64(71.19245828494051),\n",
       " 'Ingolstadt': np.float64(71.0165776348987),\n",
       " 'Eintracht Frankfurt': np.float64(70.6169902683531),\n",
       " 'VfB Stuttgart': np.float64(37.66955722879909),\n",
       " 'Hannover 96': np.float64(19.194387968792206)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo(bl_result_df, s=res[\"params\"][\"s\"], K=res[\"params\"][\"K\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480ded0-8fed-4732-ae2c-cef31a7e024c",
   "metadata": {},
   "source": [
    "As we can see, the final ranking at the end of the season is strongly correlated with the actual league table.\n",
    "But, we could try optimizing the parameters a bit further using gradient descent from those starting parameters.\n",
    "Gradient descent is a standard practice in machine learning to find parameters that allow a function to reach a minimum in terms of loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cd516fd-d225-452b-9ca3-cc2f8feb6395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Brier score = 0.17795345066574975, s = 271.14154310709904, K = 20.447738120511808\n",
      "Iteration 100: Brier score = 0.17795254370403202, s = 271.2349039633821, K = 20.35309214544007\n",
      "Iteration 200: Brier score = 0.17795199812485302, s = 271.3126315462579, K = 20.273932400837435\n",
      "Iteration 300: Brier score = 0.17795170632470167, s = 271.3735168370143, K = 20.21162764201154\n",
      "Iteration 400: Brier score = 0.17795156975407675, s = 271.4180023744578, K = 20.16588990044537\n",
      "Optimized s: 271.4477628525792, Optimized K: 20.135156178137716\n"
     ]
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "# Define the PyTorch version of predict\n",
    "def predict_torch(rating_a, rating_b, s):\n",
    "    return 1 / (1 + torch.pow(10, -(rating_a - rating_b) / s))\n",
    "\n",
    "\n",
    "# Define the PyTorch version of update_elo\n",
    "def update_elo_torch(rating_a, rating_b, outcome, s, K):\n",
    "    pred = predict_torch(rating_a, rating_b, s)\n",
    "    return rating_a + K * (outcome - pred)\n",
    "\n",
    "\n",
    "# Convert the brier_score function to work with PyTorch tensors\n",
    "def brier_score_torch(results_df, s, K):\n",
    "    # Initialize ratings with PyTorch tensors\n",
    "    unique_teams = results_df[\"home_team_name\"].unique()\n",
    "    ratings = {\n",
    "        team_name: torch.tensor(100.0, requires_grad=False)\n",
    "        for team_name in unique_teams\n",
    "    }\n",
    "\n",
    "    total_brier_score = torch.tensor(0.0, dtype=torch.float32)\n",
    "\n",
    "    for row in results_df.itertuples(index=False):\n",
    "        home_rating = ratings[row.home_team_name]\n",
    "        away_rating = ratings[row.away_team_name]\n",
    "\n",
    "        # Use the torch-based predict function\n",
    "        home_pred = predict_torch(home_rating, away_rating, s)\n",
    "        away_pred = 1 - home_pred\n",
    "\n",
    "        home_team_result = torch.tensor(\n",
    "            [row.home_team_result], dtype=torch.float32\n",
    "        )\n",
    "        away_team_result = torch.tensor(\n",
    "            [row.away_team_result], dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        # Accumulate Brier score and ensure correct shape\n",
    "        total_brier_score = total_brier_score \\\n",
    "            + torch.pow(home_pred - home_team_result, 2)\n",
    "        total_brier_score = total_brier_score \\\n",
    "            + torch.pow(away_pred - away_team_result, 2)\n",
    "\n",
    "        # Update ratings with torch-based update function\n",
    "        ratings[row.home_team_name] = update_elo_torch(\n",
    "            home_rating, away_rating, row.home_team_result, s, K\n",
    "        )\n",
    "        ratings[row.away_team_name] = update_elo_torch(\n",
    "            away_rating, home_rating, row.away_team_result, s, K\n",
    "        )\n",
    "\n",
    "    # Return the average Brier score as a tensor\n",
    "    return total_brier_score / (2 * len(results_df))\n",
    "\n",
    "\n",
    "# Initial values for s and K as torch tensors (requires gradients)\n",
    "s = torch.tensor([res[\"params\"][\"s\"]], requires_grad=True)\n",
    "K = torch.tensor([res[\"params\"][\"K\"]], requires_grad=True)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = Adam([s, K], lr=0.001)\n",
    "\n",
    "# Number of gradient descent steps\n",
    "n_iterations = 500\n",
    "\n",
    "# Perform gradient descent\n",
    "for i in range(n_iterations):\n",
    "    optimizer.zero_grad()  # Zero the gradients from the previous iteration\n",
    "\n",
    "    # Calculate the Brier score\n",
    "    loss = brier_score_torch(bl_result_df, s, K)\n",
    "\n",
    "    # Backpropagation to compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Perform a step of gradient descent\n",
    "    optimizer.step()\n",
    "\n",
    "    # Optionally, print progress\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}: Brier score = {loss.item()}, s = {s.item()}, K = {K.item()}\")\n",
    "\n",
    "# Final optimized values of s and K\n",
    "print(f\"Optimized s: {s.item()}, Optimized K: {K.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b9b7198-b12b-4df9-a32b-0e7e1190b29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bayern Munich': 238.11614695578442,\n",
       " 'Borussia Dortmund': 202.10731690794827,\n",
       " 'Bayer Leverkusen': 155.58162112932683,\n",
       " 'Borussia Mönchengladbach': 134.8976205950394,\n",
       " 'Schalke 04': 117.80211535227875,\n",
       " 'FSV Mainz 05': 106.9566223178877,\n",
       " 'Hertha Berlin': 95.6603558234831,\n",
       " 'FC Köln': 95.37158298186573,\n",
       " 'Wolfsburg': 83.44786249701849,\n",
       " 'Augsburg': 81.22629511106862,\n",
       " 'Hoffenheim': 80.08479250444809,\n",
       " 'Werder Bremen': 77.92219184991505,\n",
       " 'Hamburger SV': 74.46172196837092,\n",
       " 'Darmstadt 98': 71.39588595656109,\n",
       " 'Ingolstadt': 71.31005191484432,\n",
       " 'Eintracht Frankfurt': 70.64756396595439,\n",
       " 'VfB Stuttgart': 38.3064811665141,\n",
       " 'Hannover 96': 19.632316449702756}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elo(bl_result_df, s=s.item(), K=K.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a6b06-803c-4247-9f3f-43c3492d0930",
   "metadata": {},
   "source": [
    "Gradient descent does not change the final rankings, but it found a slightly lower K value and higher s value indincating slower ELO updates and more conservative outcome predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81528d00-2f82-41e6-b355-bde3a65ae306",
   "metadata": {},
   "source": [
    "## 2. Task 2 - Research Problem Corners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c66ac6-d9b1-4596-ba6f-805c631eec7a",
   "metadata": {},
   "source": [
    "### a. Use the whole data set of Free Statsbomb Data to help you find general offensive trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d881ada8-c654-4f7a-9cfc-6b1a9033c094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aerial_won: boolean (nullable = true)\n",
      " |-- angle: double (nullable = true)\n",
      " |-- assisted_shot_id: string (nullable = true)\n",
      " |-- backheel: boolean (nullable = true)\n",
      " |-- body_part: struct (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- cross: boolean (nullable = true)\n",
      " |-- cut_back: boolean (nullable = true)\n",
      " |-- deflected: boolean (nullable = true)\n",
      " |-- end_location: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- goal_assist: boolean (nullable = true)\n",
      " |-- height: struct (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- inswinging: boolean (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- miscommunication: boolean (nullable = true)\n",
      " |-- no_touch: boolean (nullable = true)\n",
      " |-- outcome: struct (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- outswinging: boolean (nullable = true)\n",
      " |-- recipient: struct (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- shot_assist: boolean (nullable = true)\n",
      " |-- straight: boolean (nullable = true)\n",
      " |-- switch: boolean (nullable = true)\n",
      " |-- technique: struct (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- through_ball: boolean (nullable = true)\n",
      " |-- type: struct (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# end_location -> cat\n",
    "# body_part -> inswinging, outswinging\n",
    "# \n",
    "\n",
    "df.select(\"pass.*\").printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
